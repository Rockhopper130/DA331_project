{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers, models, optimizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import LSTM,Dropout,Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import LSTM, Conv1D, MaxPooling1D, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word count</th>\n",
       "      <th>count_word</th>\n",
       "      <th>count_unique_word</th>\n",
       "      <th>count_letters</th>\n",
       "      <th>count_punctuations</th>\n",
       "      <th>count_words_upper</th>\n",
       "      <th>count_words_title</th>\n",
       "      <th>count_stopwords</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>word_unique_percent</th>\n",
       "      <th>punct_percent</th>\n",
       "      <th>reviews_pre</th>\n",
       "      <th>embeddings_distilbert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "      <td>208</td>\n",
       "      <td>1761</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>133</td>\n",
       "      <td>4.739414</td>\n",
       "      <td>67.752443</td>\n",
       "      <td>25.407166</td>\n",
       "      <td>one reviewer mentioned watching 1 oz episode h...</td>\n",
       "      <td>[ 2.25813061e-01  3.54351997e-02  5.05604744e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "      <td>114</td>\n",
       "      <td>998</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>66</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>70.370370</td>\n",
       "      <td>27.160494</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>[-4.65010226e-01  6.32754207e-01  2.78978735e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>121</td>\n",
       "      <td>926</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>76</td>\n",
       "      <td>4.584337</td>\n",
       "      <td>72.891566</td>\n",
       "      <td>24.096386</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>[ 1.80858865e-01  4.71553922e-01  6.99151278e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>138</td>\n",
       "      <td>96</td>\n",
       "      <td>748</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>62</td>\n",
       "      <td>4.427536</td>\n",
       "      <td>69.565217</td>\n",
       "      <td>30.434783</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>[ 5.36763310e-01  4.89160836e-01  4.62464690e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "      <td>152</td>\n",
       "      <td>1317</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>96</td>\n",
       "      <td>4.730435</td>\n",
       "      <td>66.086957</td>\n",
       "      <td>24.347826</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>[-3.51513296e-01  4.82253611e-01  6.09883726e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  word count  count_word  count_unique_word  count_letters  \\\n",
       "0          1         307         307                208           1761   \n",
       "1          1         162         162                114            998   \n",
       "2          1         166         166                121            926   \n",
       "3          0         138         138                 96            748   \n",
       "4          1         230         230                152           1317   \n",
       "\n",
       "   count_punctuations  count_words_upper  count_words_title  count_stopwords  \\\n",
       "0                  78                  8                 36              133   \n",
       "1                  44                  2                 12               66   \n",
       "2                  40                  3                 20               76   \n",
       "3                  42                  3                 13               62   \n",
       "4                  56                  1                 31               96   \n",
       "\n",
       "   mean_word_len  word_unique_percent  punct_percent  \\\n",
       "0       4.739414            67.752443      25.407166   \n",
       "1       5.166667            70.370370      27.160494   \n",
       "2       4.584337            72.891566      24.096386   \n",
       "3       4.427536            69.565217      30.434783   \n",
       "4       4.730435            66.086957      24.347826   \n",
       "\n",
       "                                         reviews_pre  \\\n",
       "0  one reviewer mentioned watching 1 oz episode h...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically family little boy jake think zombie ...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                               embeddings_distilbert  \n",
       "0  [ 2.25813061e-01  3.54351997e-02  5.05604744e-...  \n",
       "1  [-4.65010226e-01  6.32754207e-01  2.78978735e-...  \n",
       "2  [ 1.80858865e-01  4.71553922e-01  6.99151278e-...  \n",
       "3  [ 5.36763310e-01  4.89160836e-01  4.62464690e-...  \n",
       "4  [-3.51513296e-01  4.82253611e-01  6.09883726e-...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/distilbert_imdb2.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['reviews_pre'], data['sentiment'],test_size=0.2, random_state=0)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought wonderful way spend time hot summer weekend sitting air conditioned theater watching lighthearted comedy plot simplistic dialogue witty character likable even well bread suspected serial killer may disappointed realize match point 2 risk addiction thought proof woody allen still fully control style many u grown lovethis would laughed one woodys comedy year dare say decade never impressed scarlet johanson managed tone sexy image jumped right average spirited young womanthis may crown jewel career wittier devil wear prada interesting superman great comedy go see friend\n",
      "[363, 158, 71, 9, 26, 356, 105, 3, 1791, 3460, 3404, 4712, 2294, 1654, 15, 134, 2, 140, 363, 130, 731, 790, 2, 1518, 15, 1138, 29, 1936, 9, 2685, 102, 1138, 3, 675, 1, 120, 48, 177, 120, 31, 1327, 105, 29, 3, 38, 2, 19, 127, 521, 4227, 924, 1138, 4198, 3557, 151, 1523, 1263, 440, 1138, 311, 269, 1939, 2267, 193, 3307, 149, 1138, 3532, 5, 144, 1138, 1213, 41, 40, 41, 233, 445, 3606, 2000, 62, 3, 46, 101, 1341, 3472, 101, 127, 243, 227, 292, 550, 712, 2147, 1562, 48, 28, 53, 460, 264, 2963, 1025, 4121, 1085, 187, 232, 275, 2492, 59, 35, 2104, 2, 721, 88, 59, 2944, 929, 7, 11, 41, 161, 815, 280, 4, 139, 703, 563, 508, 279, 104, 27, 4, 31, 3176, 2802, 1512, 461, 1268, 1089, 36, 2, 60, 17, 148, 39, 219, 2087, 451, 799, 435, 58, 13, 143, 80, 1138, 2554, 3460, 53, 9, 851, 815, 124, 241, 2155, 4530, 2083, 1973, 26, 1151, 51, 1507, 2, 3, 644, 4121, 1138, 234, 4386, 21, 630, 223, 628, 84, 478, 694, 1337, 3697, 1, 234, 162, 19, 134, 1138, 2, 48, 5, 788, 283, 302, 763, 1082, 184, 2365, 4587, 1031, 134, 16, 4146, 27, 821, 120, 433, 53, 561, 561, 53, 3, 1654, 53, 3167, 1290, 706, 9, 2, 122, 2628, 866, 134, 149, 763, 1082, 1449, 2576, 288, 3830, 2740, 2, 29, 19, 1740, 548, 2406, 274]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(data.reviews_pre)\n",
    "\n",
    "X_train1 = tokenizer.texts_to_sequences(X_train)\n",
    "X_valid1 = tokenizer.texts_to_sequences(X_valid)\n",
    "X_test1 = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "print(X_train[2])\n",
    "print(X_train1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average length: 99.8\n",
      "max length: 949\n"
     ]
    }
   ],
   "source": [
    "seq_lens = [len(s) for s in X_train1]\n",
    "print(\"average length: %0.1f\" % np.mean(seq_lens))\n",
    "print(\"max length: %d\" % max(seq_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2147 1562   48   28   53  460  264 2963 1025 4121 1085  187  232  275\n",
      " 2492   59   35 2104    2  721   88   59 2944  929    7   11   41  161\n",
      "  815  280    4  139  703  563  508  279  104   27    4   31 3176 2802\n",
      " 1512  461 1268 1089   36    2   60   17  148   39  219 2087  451  799\n",
      "  435   58   13  143   80 1138 2554 3460   53    9  851  815  124  241\n",
      " 2155 4530 2083 1973   26 1151   51 1507    2    3  644 4121 1138  234\n",
      " 4386   21  630  223  628   84  478  694 1337 3697    1  234  162   19\n",
      "  134 1138    2   48    5  788  283  302  763 1082  184 2365 4587 1031\n",
      "  134   16 4146   27  821  120  433   53  561  561   53    3 1654   53\n",
      " 3167 1290  706    9    2  122 2628  866  134  149  763 1082 1449 2576\n",
      "  288 3830 2740    2   29   19 1740  548 2406  274]\n"
     ]
    }
   ],
   "source": [
    "maxlen = 150\n",
    "\n",
    "X_train1 = pad_sequences(X_train1, padding='post', maxlen=maxlen)\n",
    "X_valid1 = pad_sequences(X_valid1, padding='post', maxlen=maxlen)\n",
    "X_test1 = pad_sequences(X_test1, padding='post', maxlen=maxlen)\n",
    "\n",
    "print(X_train1[2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 150, 50)           10554700  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7500)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                75010     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10629721 (40.55 MB)\n",
      "Trainable params: 10629721 (40.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "callback = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 0.6714 - accuracy: 0.6025 - val_loss: 0.5861 - val_accuracy: 0.7467\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 2s 52ms/step - loss: 0.4046 - accuracy: 0.8481 - val_loss: 0.3198 - val_accuracy: 0.8620\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 2s 52ms/step - loss: 0.2557 - accuracy: 0.8989 - val_loss: 0.2904 - val_accuracy: 0.8723\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 2s 53ms/step - loss: 0.2048 - accuracy: 0.9232 - val_loss: 0.2936 - val_accuracy: 0.8742\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.1698 - accuracy: 0.9411 - val_loss: 0.2992 - val_accuracy: 0.8760\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train1, y_train,epochs=10,verbose=True,validation_data=(X_valid1, y_valid),batch_size=1000,callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 719us/step\n",
      "Accuracy : 0.8752\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test1)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int) \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(f\"Accuracy : {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/NN.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 150, 50)           10554700  \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               60400     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10615201 (40.49 MB)\n",
      "Trainable params: 10615201 (40.49 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = 32\n",
    "callback = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/141 [==============================] - 109s 762ms/step - loss: 0.5599 - accuracy: 0.6677 - val_loss: 0.3125 - val_accuracy: 0.8695\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 102s 726ms/step - loss: 0.2918 - accuracy: 0.8882 - val_loss: 0.2891 - val_accuracy: 0.8808\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 97s 689ms/step - loss: 0.2598 - accuracy: 0.9042 - val_loss: 0.2922 - val_accuracy: 0.8790\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 97s 691ms/step - loss: 0.2281 - accuracy: 0.9162 - val_loss: 0.2870 - val_accuracy: 0.8790\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 99s 701ms/step - loss: 0.2165 - accuracy: 0.9201 - val_loss: 0.3053 - val_accuracy: 0.8752\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 100s 707ms/step - loss: 0.2021 - accuracy: 0.9272 - val_loss: 0.3654 - val_accuracy: 0.8773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2ce280e80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train1, y_train, epochs=10, batch_size=256,verbose = 1,validation_data=(X_valid1,y_valid),callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 13s 40ms/step\n",
      "Accuracy : 0.8746\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test1)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int) \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(f\"Accuracy : {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/LSTM.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 150, 50)           10554700  \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 150, 32)           4832      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 75, 32)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               53200     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10612833 (40.48 MB)\n",
      "Trainable params: 10612833 (40.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = 32\n",
    "callback = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/141 [==============================] - 34s 236ms/step - loss: 0.5118 - accuracy: 0.7021 - val_loss: 0.3072 - val_accuracy: 0.8777\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 32s 227ms/step - loss: 0.2582 - accuracy: 0.8988 - val_loss: 0.2814 - val_accuracy: 0.8820\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 30s 210ms/step - loss: 0.2172 - accuracy: 0.9192 - val_loss: 0.2827 - val_accuracy: 0.8848\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 31s 217ms/step - loss: 0.1889 - accuracy: 0.9323 - val_loss: 0.3286 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x12891f910>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train1, y_train, epochs=10, batch_size=256,verbose = 1,validation_data=(X_valid1,y_valid),callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step\n",
      "Accuracy : 0.8789\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test1)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int) \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(f\"Accuracy : {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/CNN.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "city",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
